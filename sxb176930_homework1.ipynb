{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "emFdR69I9pDo"
   },
   "source": [
    "# Acknowledgement:\n",
    "### Notebook inspired from following sources:\n",
    "1. https://towardsdatascience.com/sentiment-analysis-with-text-mining-13dd2b33de27\n",
    "2. https://www.youtube.com/watch?v=ujId4ipkBio\n",
    "3. https://stackoverflow.com/questions/43018030/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "it0GjE6X9q6Q"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FW77K3wM_Tb_"
   },
   "source": [
    "# Importing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QYoE0Gca_N__"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\", encoding='ISO-8859-1')\n",
    "test = pd.read_csv(\"test.csv\", encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "2DCwMJND_biq",
    "outputId": "80df0663-9c75-4a31-8093-643aa6e59bc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id                                               text  Target\n",
      "0   1  @USAirways  ! THE WORST in customer service. @...      -1\n",
      "1   2  @united call wait times are over 20 minutes an...      -1\n",
      "2   3  @JetBlue what's up with the random delay on fl...      -1\n",
      "3   4  @AmericanAir Good morning!  Wondering why my p...       0\n",
      "4   5  @united UA 746. Pacific Rim and Date Night cut...      -1\n",
      "     id                                               text\n",
      "0  7322  @AmericanAir In car gng to DFW. Pulled over 1h...\n",
      "1  7323  @AmericanAir after all, the plane didnÂÃÂªt ...\n",
      "2  7324  @SouthwestAir can't believe how many paying cu...\n",
      "3  7325  @USAirways I can legitimately say that I would...\n",
      "4  7326  @AmericanAir still no response from AA. great ...\n"
     ]
    }
   ],
   "source": [
    "# Understanding the data\n",
    "print(train.head())\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "LaLuYJ2O_j3f",
    "outputId": "2859833d-e91d-45a0-b094-91c12eebbec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: (7320, 3)\n",
      "Test data: (7320, 2)\n"
     ]
    }
   ],
   "source": [
    "# Shape of train and test data\n",
    "print(\"Train data:\", train.shape)\n",
    "print(\"Test data:\", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QACszo9aTOkQ"
   },
   "source": [
    "# Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3p3ySj5FcPM9"
   },
   "outputs": [],
   "source": [
    "# Replacing short words \n",
    "shortwords_dict = {\n",
    "    \"doesn't\" : \"does not\",\n",
    "    \"didn't\" : \"did not\",\n",
    "    \"don't\" : \"do not\",\n",
    "    \"can't\" : \"can not\",\n",
    "    \"couldn't\" : \"could not\",\n",
    "    \"could've\" : \"could have\",\n",
    "    \"aren't\" : \"are not\",\n",
    "    \"ain't\" : \"is not\",\n",
    "    \"isn't\" : \"is not\",\n",
    "    \"it's\" : \"it is\",\n",
    "    \"i'll\" : \"i will\",\n",
    "    \"i'd\" : \"i would\",\n",
    "    \"i've\" : \"i have\",\n",
    "    \"i'm\" : \"i am\",\n",
    "    \"he's\" : \"he is\",\n",
    "    \"he'll\" : \"he will\",\n",
    "    \"hadn't\" : \"had not\",\n",
    "    \"hasn't\" : \"has not\",\n",
    "    \"haven't\" : \"have not\",\n",
    "    \"how's\" : \"how is\",\n",
    "    \"she'll\" : \"she will\",\n",
    "    \"she's\" : \"she is\",\n",
    "    \"should've\" : \"should have\",\n",
    "    \"shouldn't\" : \"should not\",\n",
    "    \"let's\" : \"let us\",\n",
    "    \"that's\" : \"that is\",\n",
    "    \"they're\" : \"they are\",\n",
    "    \"they've\" : \"they have\",\n",
    "    \"they'll\" : \"they will\",\n",
    "    \"that'd\" : \"that would\",\n",
    "    \"'cause\" : \"because\",\n",
    "    \"ma'am\" : \"madam\",\n",
    "    \"might've\" : \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"we'd\" : \"we would\",\n",
    "    \"we're\" : \"we are\",\n",
    "    \"we've\" : \"we have\",\n",
    "    \"we'll\" : \"we will\",\n",
    "    \"weren't\" : \"were not\",\n",
    "    \"what'll\" : \"what will\",\n",
    "    \"what's\" : \"what is\",\n",
    "    \"won't\" : \"will not\",\n",
    "    \"wouldn't\" : \"would not\",\n",
    "    \"would've\" : \"would have\",\n",
    "    \"y'all\" : \"you all\",\n",
    "    \"you'd\" : \"you would\",\n",
    "    \"you'll\" : \"you will\",\n",
    "    \"you're\" : \"you are\",\n",
    "    \"you've\" : \"you have\"\n",
    "}\n",
    "\n",
    "def replacesw(text):\n",
    "   tokens = text.split()\n",
    "   replaced = []\n",
    "   for token in tokens:\n",
    "     replaced.append(shortwords_dict[token] if token in shortwords_dict else token)\n",
    "   text = \" \".join(word for word in replaced)\n",
    "   return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mncpWcK9EPEO"
   },
   "outputs": [],
   "source": [
    "# Finding and replacing emoticons\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import regex as re \n",
    "\n",
    "emoticon = {\n",
    "    ':D': 'laughface',\n",
    "    ':-D': 'laughface',\n",
    "    ':)': 'smileface',\n",
    "    ':-)': 'smileface',\n",
    "    ':(': 'sadface',\n",
    "    ':-(': 'sadface',\n",
    "    ':/': 'troubledface',\n",
    "    ':-/': 'troubledface',\n",
    "    ':|': 'straightface',\n",
    "    ':-|': 'straightface',\n",
    "\n",
    "}\n",
    "\n",
    "def emoticonToWord(text):\n",
    "  tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "  tokens = tokenizer.tokenize(text)\n",
    "  replaced = []\n",
    "  for token in tokens:\n",
    "    replaced.append(emoticon[token] if token in emoticon else token)\n",
    "  text = \" \".join(word for word in replaced)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nZv_0MmmRjDi"
   },
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "def clean(text):\n",
    "  # Replacing emoticons with text\n",
    "  text = emoticonToWord(text)\n",
    "  # Replacing short words like can't, i'd, etc\n",
    "  text = replacesw(text)\n",
    "  # Removing @ mentions\n",
    "  text = re.sub(r'@\\w+','',text)\n",
    "  # Removing words starting with & i.e. &amp, &lt etc\n",
    "  text = re.sub(r'&\\w+','',text)\n",
    "  # Replacing period with a space\n",
    "  text = re.sub(r'\\.',' ',text)\n",
    "  # Replacing / with or\n",
    "  text = re.sub(r'/',' or ',text)\n",
    "  # Removing punctuations and special characters and # symbol at the beginning of word\n",
    "  text = re.sub(r'[^A-Za-z0-9\\s]','',text)\n",
    "  # Removing hyperlinks\n",
    "  text = re.sub(r'https?\\w+','',text)\n",
    "  # Removing double spaces\n",
    "  text = re.sub(r'\\s+',' ',text)\n",
    "  # Removing digits\n",
    "  text = re.sub(r'\\d+','',text)\n",
    "  # Converting text to lower case\n",
    "  text = text.lower()\n",
    "\n",
    "  return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6NL9yXk5TT9Z"
   },
   "source": [
    "## Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A2yU8OWhTEfC"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer \n",
    "stemmer = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvM6g4YmTfBT"
   },
   "outputs": [],
   "source": [
    "train['text'] = train['text'].apply(lambda text: \" \".join(stemmer.stem(token) for token in text.split()))\n",
    "test['text'] = test['text'].apply(lambda text: \" \".join(stemmer.stem(token) for token in text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "dPPOMMJQT7lA",
    "outputId": "c1615244-9d36-4916-9482-d451444d3336"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "   Id                                               text  Target\n",
      "0   1  the worst in custom servic call for over a mon...      -1\n",
      "1   2  call wait time are over minut and airport wait...      -1\n",
      "2   3  what is up with the random delay on flight ani...      -1\n",
      "3   4  good morn wonder whi my pretsa check wa not on...       0\n",
      "4   5  ua pacif rim and date night cut out not consta...      -1\n",
      "Test data\n",
      "     id                                               text\n",
      "0  7322  in car gng to dfw pull over hr ago veri ici ro...\n",
      "1  7323  after all the plane didn t land in ident or wo...\n",
      "2  7324  can not believ how mani pay custom you left hi...\n",
      "3  7325  i can legitim say that i would have rather dri...\n",
      "4  7326             still no respons from aa great job guy\n"
     ]
    }
   ],
   "source": [
    "# Printing train and test data\n",
    "print(\"Train data\")\n",
    "print(train.head())\n",
    "print(\"Test data\")\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RdQrbx7XxZCO"
   },
   "outputs": [],
   "source": [
    "#from nltk.corpus import wordnet\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#def get_part_of_speech_tags(token):\n",
    "#    tag_dict = {\"J\": wordnet.ADJ,\n",
    "#                \"N\": wordnet.NOUN,\n",
    "#                \"V\": wordnet.VERB,\n",
    "#                \"R\": wordnet.ADV}\n",
    "#    \n",
    "#    tag = nltk.pos_tag([token])[0][1][0].upper()\n",
    "#    \n",
    "#    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lwoAoCupyD0K"
   },
   "outputs": [],
   "source": [
    "#nltk.download('wordnet')\n",
    "#from nltk.stem import WordNetLemmatizer \n",
    "#lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yL9keg_2xZTm"
   },
   "outputs": [],
   "source": [
    "#train['text'] = train['text'].apply(lambda sentence:\" \".join(lemmatizer.lemmatize(word, get_part_of_speech_tags(word)) for word in sentence.lower().split()))\n",
    "#test['text'] = test['text'].apply(lambda sentence:\" \".join(lemmatizer.lemmatize(word, get_part_of_speech_tags(word)) for word in sentence.lower().split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S8l-UlAwUVOy"
   },
   "source": [
    "# Vectorization and Machine Learning Models (Without Removing Stop Words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kVGkq0JLUc4h"
   },
   "source": [
    "### Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zhBWMyYIT-wV"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import  classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X0RTdDikUljr"
   },
   "outputs": [],
   "source": [
    "# Splitting the train data into train and test\n",
    "X = train['text']\n",
    "y = train['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3HTZucfWWBzW"
   },
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0TvOw-y8Wiv4"
   },
   "source": [
    "#### Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GiavhDvUV4CY"
   },
   "outputs": [],
   "source": [
    "# Creating a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('v', CountVectorizer(strip_accents='ascii', max_df=0.5)),\n",
    "    ('c', MultinomialNB(fit_prior=True, class_prior=None))\n",
    "    ])\n",
    "\n",
    "# Setting parameters\n",
    "params = {\n",
    "   # 'v__max_df': [0.3,0.5,0.8],\n",
    "    'v__ngram_range': [(1,1),(1,2),(1,3),(1,4)],\n",
    "    'c__alpha': [0.25,0.5,0.75]\n",
    "}\n",
    "\n",
    "gridSearchNB = GridSearchCV(pipeline,params,cv=10,n_jobs=-1, scoring=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "colab_type": "code",
    "id": "UototGEpV9Zg",
    "outputId": "b1cb09af-ada0-4ede-cb68-d4acc1418f49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('v',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=0.5,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents='ascii',\n",
       "                                                        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                                        tokenizer=None,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('c',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'c__alpha': [0.25, 0.5, 0.75],\n",
       "                         'v__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_macro', verbose=0)"
      ]
     },
     "execution_count": 411,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearchNB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "id": "IOftpvmEV_0A",
    "outputId": "c51ca870-3c16-4c33-a921-beb6b262ce5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'c__alpha': 0.25, 'v__ngram_range': (1, 2)}\n",
      "Train Score: 0.97\n",
      "Test Score: 0.69\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters: \", gridSearchNB.best_params_)\n",
    "print(\"Train Score: {:.2f}\".format(gridSearchNB.score(X_train,y_train)))\n",
    "print(\"Test Score: {:.2f}\".format(gridSearchNB.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "colab_type": "code",
    "id": "4wT4lOkOWZIk",
    "outputId": "70f627a1-c757-4768-b199-86d5ea162819"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.98      0.98      0.98      3634\n",
      "           0       0.95      0.94      0.95      1241\n",
      "           1       0.96      0.98      0.97       981\n",
      "\n",
      "    accuracy                           0.97      5856\n",
      "   macro avg       0.96      0.97      0.97      5856\n",
      "weighted avg       0.97      0.97      0.97      5856\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.95      0.87       932\n",
      "           0       0.66      0.42      0.51       295\n",
      "           1       0.82      0.60      0.69       237\n",
      "\n",
      "    accuracy                           0.79      1464\n",
      "   macro avg       0.76      0.66      0.69      1464\n",
      "weighted avg       0.78      0.79      0.77      1464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,gridSearchNB.predict(X_train)))\n",
    "print(classification_report(y_test,gridSearchNB.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wo7yfeEZWlda"
   },
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Rr2wnJLWqhj"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "obo7as69Wfjf"
   },
   "outputs": [],
   "source": [
    "# Creating a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('v', CountVectorizer(strip_accents='ascii', max_df =0.5)),\n",
    "    ('lr', LogisticRegression(solver='lbfgs', max_iter=10000))\n",
    "    ])\n",
    "\n",
    "# Setting parameters\n",
    "params = {\n",
    "    'v__ngram_range': [(1,1),(1,2),(1,3),(1,4)],\n",
    "    'lr__penalty': ['l1','l2'],\n",
    "    'lr__C': [0.1, 0.25, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "gridSearchLR = GridSearchCV(pipeline,params,cv=5,n_jobs=-1, scoring=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "colab_type": "code",
    "id": "McnCtzMoWvdo",
    "outputId": "3f1bf1b9-b5a5-49a6-b538-da3a49458ba0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('v',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=0.5,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents='ascii',\n",
       "                                                        token_pattern='(?u)...\n",
       "                                                           multi_class='auto',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'lr__C': [0.1, 0.25, 0.5, 1.0],\n",
       "                         'lr__penalty': ['l1', 'l2'],\n",
       "                         'v__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_macro', verbose=0)"
      ]
     },
     "execution_count": 549,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearchLR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "id": "XCH7tgxJWxdG",
    "outputId": "150aff6e-342b-4bd8-cb7e-8b72095beb59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'lr__C': 1.0, 'lr__penalty': 'l2', 'v__ngram_range': (1, 2)}\n",
      "Train Score: 0.99\n",
      "Test Score: 0.75\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters: \", gridSearchLR.best_params_)\n",
    "print(\"Train Score: {:.2f}\".format(gridSearchLR.score(X_train,y_train)))\n",
    "print(\"Test Score: {:.2f}\".format(gridSearchLR.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "colab_type": "code",
    "id": "wmfdjkjWW1-z",
    "outputId": "50c4c4f1-62be-45c8-eb24-cc0db4dc1d01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00      3634\n",
      "           0       0.99      0.99      0.99      1241\n",
      "           1       0.99      0.99      0.99       981\n",
      "\n",
      "    accuracy                           1.00      5856\n",
      "   macro avg       0.99      0.99      0.99      5856\n",
      "weighted avg       1.00      1.00      1.00      5856\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.92      0.89       932\n",
      "           0       0.69      0.62      0.65       295\n",
      "           1       0.81      0.65      0.72       237\n",
      "\n",
      "    accuracy                           0.82      1464\n",
      "   macro avg       0.79      0.73      0.75      1464\n",
      "weighted avg       0.81      0.82      0.81      1464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,gridSearchLR.predict(X_train)))\n",
    "print(classification_report(y_test,gridSearchLR.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GEjOAJUudUxM"
   },
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jb92Tx5tdqYm"
   },
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "7BS_4vVIXie7",
    "outputId": "eb1ec70f-18b0-4688-ecb1-4d1c27966e5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.89\n",
      "Test score: 0.79\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(strip_accents='ascii', max_df =0.5)\n",
    "X_trainxgb = cv.fit_transform(X_train)\n",
    "X_testxgb = cv.transform(X_test)\n",
    "\n",
    "xgb = XGBClassifier(objective='multi:softmax', seed=0, missing=None, max_depth=9,early_stopping_rounds = 5)\n",
    "xgb.fit(X_trainxgb,y_train)\n",
    "\n",
    "print(\"Train score: {:.2f}\".format(xgb.score(X_trainxgb,y_train)))\n",
    "print(\"Test score: {:.2f}\".format(xgb.score(X_testxgb,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "colab_type": "code",
    "id": "ZzYGP2XWfQcD",
    "outputId": "5b419923-2a55-4217-8a6d-02e7a1098c67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.96      0.94      3634\n",
      "           0       0.82      0.80      0.81      1241\n",
      "           1       0.92      0.78      0.84       981\n",
      "\n",
      "    accuracy                           0.89      5856\n",
      "   macro avg       0.88      0.85      0.86      5856\n",
      "weighted avg       0.89      0.89      0.89      5856\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.92      0.87       932\n",
      "           0       0.70      0.54      0.61       295\n",
      "           1       0.75      0.60      0.67       237\n",
      "\n",
      "    accuracy                           0.79      1464\n",
      "   macro avg       0.76      0.69      0.72      1464\n",
      "weighted avg       0.79      0.79      0.78      1464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,xgb.predict(X_trainxgb)))\n",
    "print(classification_report(y_test,xgb.predict(X_testxgb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L6ycByWcg2hZ"
   },
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "us7Jk09obBhk"
   },
   "outputs": [],
   "source": [
    "# Creating a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('v', TfidfVectorizer(norm=None, max_df=0.5)),\n",
    "    ('c', MultinomialNB(fit_prior=True, class_prior=None))\n",
    "    ])\n",
    "\n",
    "# Setting parameters\n",
    "params = {\n",
    "    'v__ngram_range': [(1,1),(1,2),(1,3),(1,4)],\n",
    "    'c__alpha': [0.25,0.5,0.75]\n",
    "}\n",
    "\n",
    "gridSearchNBtfidf = GridSearchCV(pipeline,params,cv=10,n_jobs=-1, scoring=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "colab_type": "code",
    "id": "EyrHoVJ9g79U",
    "outputId": "abbb0035-36eb-4e72-f4a8-1c0a3a770341"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('v',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=0.5,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm=None,\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accent...\n",
       "                                                        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                                        tokenizer=None,\n",
       "                                                        use_idf=True,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('c',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'c__alpha': [0.25, 0.5, 0.75],\n",
       "                         'v__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_macro', verbose=0)"
      ]
     },
     "execution_count": 421,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearchNBtfidf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "id": "sK68dS7ShEGF",
    "outputId": "b9f0be88-fbd1-4420-cf12-ca0d22a59b49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'c__alpha': 0.75, 'v__ngram_range': (1, 2)}\n",
      "Train Score: 0.98\n",
      "Test Score: 0.69\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters: \", gridSearchNBtfidf.best_params_)\n",
    "print(\"Train Score: {:.2f}\".format(gridSearchNBtfidf.score(X_train,y_train)))\n",
    "print(\"Test Score: {:.2f}\".format(gridSearchNBtfidf.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "colab_type": "code",
    "id": "c-ot36fChYDe",
    "outputId": "8260ae29-0b07-4921-83b6-5fea8759cb13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.99      0.99      3634\n",
      "           0       0.97      0.97      0.97      1241\n",
      "           1       0.97      0.99      0.98       981\n",
      "\n",
      "    accuracy                           0.99      5856\n",
      "   macro avg       0.98      0.99      0.98      5856\n",
      "weighted avg       0.99      0.99      0.99      5856\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.90      0.87       932\n",
      "           0       0.63      0.48      0.55       295\n",
      "           1       0.68      0.65      0.67       237\n",
      "\n",
      "    accuracy                           0.78      1464\n",
      "   macro avg       0.71      0.68      0.69      1464\n",
      "weighted avg       0.77      0.78      0.77      1464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,gridSearchNBtfidf.predict(X_train)))\n",
    "print(classification_report(y_test,gridSearchNBtfidf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aHvlKLVqnEAt"
   },
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8qKFH86hhcej"
   },
   "outputs": [],
   "source": [
    "# Creating a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('v', TfidfVectorizer(norm=None, max_df=0.5)),\n",
    "    ('lr', LogisticRegression(solver='lbfgs'))\n",
    "    ])\n",
    "\n",
    "# Setting parameters\n",
    "params = {\n",
    "    'v__ngram_range': [(1,1),(1,2),(1,3),(1,4)],\n",
    "    'lr__penalty': ['l1','l2'],\n",
    "    'lr__C': [0.1, 0.25, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "gridSearchLRtfidf = GridSearchCV(pipeline,params,cv=5,n_jobs=-1, scoring=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "colab_type": "code",
    "id": "JimA2Ji8hrG_",
    "outputId": "79c62494-af19-4f9b-87c9-559d5db08e3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('v',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=0.5,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm=None,\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents...\n",
       "                                                           multi_class='auto',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'lr__C': [0.1, 0.25, 0.5, 1.0],\n",
       "                         'lr__penalty': ['l1', 'l2'],\n",
       "                         'v__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_macro', verbose=0)"
      ]
     },
     "execution_count": 425,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearchLRtfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "id": "f9mHZ8M4hro6",
    "outputId": "3f459844-6860-41b2-fe50-da40b9f3ee8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'lr__C': 0.1, 'lr__penalty': 'l2', 'v__ngram_range': (1, 2)}\n",
      "Train Score: 1.00\n",
      "Test Score: 0.75\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters: \", gridSearchLRtfidf.best_params_)\n",
    "print(\"Train Score: {:.2f}\".format(gridSearchLRtfidf.score(X_train,y_train)))\n",
    "print(\"Test Score: {:.2f}\".format(gridSearchLRtfidf.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "colab_type": "code",
    "id": "0auL1aSShro_",
    "outputId": "6cf12fac-fffe-4bdb-f5aa-6d4a4a75950c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00      3634\n",
      "           0       1.00      0.99      1.00      1241\n",
      "           1       0.99      1.00      0.99       981\n",
      "\n",
      "    accuracy                           1.00      5856\n",
      "   macro avg       1.00      1.00      1.00      5856\n",
      "weighted avg       1.00      1.00      1.00      5856\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.92      0.88       932\n",
      "           0       0.68      0.59      0.63       295\n",
      "           1       0.81      0.66      0.73       237\n",
      "\n",
      "    accuracy                           0.81      1464\n",
      "   macro avg       0.78      0.73      0.75      1464\n",
      "weighted avg       0.81      0.81      0.81      1464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,gridSearchLRtfidf.predict(X_train)))\n",
    "print(classification_report(y_test,gridSearchLRtfidf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UCo7xw8mf7lm"
   },
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X_I04Clff6KU"
   },
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "8PY9EvMSf6KX",
    "outputId": "0df20fc0-ae3e-4044-abd6-916571a77ce4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.89\n",
      "Test score: 0.79\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(norm=None, max_df =0.5)\n",
    "X_trainxgb = tfidf.fit_transform(X_train)\n",
    "X_testxgb = tfidf.transform(X_test)\n",
    "\n",
    "xgbtfidf = XGBClassifier(objective='multi:softmax', seed=0, missing=None, max_depth=9,early_stopping_rounds = 5)\n",
    "xgbtfidf.fit(X_trainxgb,y_train)\n",
    "\n",
    "print(\"Train score: {:.2f}\".format(xgbtfidf.score(X_trainxgb,y_train)))\n",
    "print(\"Test score: {:.2f}\".format(xgbtfidf.score(X_testxgb,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "colab_type": "code",
    "id": "xoy2tvXOf6KZ",
    "outputId": "b9958b16-3651-40c2-d645-af05fbd43db7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.96      0.94      3634\n",
      "           0       0.82      0.80      0.81      1241\n",
      "           1       0.92      0.78      0.84       981\n",
      "\n",
      "    accuracy                           0.89      5856\n",
      "   macro avg       0.88      0.85      0.86      5856\n",
      "weighted avg       0.89      0.89      0.89      5856\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.92      0.87       932\n",
      "           0       0.70      0.54      0.61       295\n",
      "           1       0.75      0.60      0.67       237\n",
      "\n",
      "    accuracy                           0.79      1464\n",
      "   macro avg       0.76      0.69      0.72      1464\n",
      "weighted avg       0.79      0.79      0.78      1464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,xgbtfidf.predict(X_trainxgb)))\n",
    "print(classification_report(y_test,xgbtfidf.predict(X_testxgb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ezKNt_rQNvxD"
   },
   "source": [
    "# Vectorization and Machine Learning Models (With removing Stop Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "s2CZUm9eNclj",
    "outputId": "35e25687-5a2b-46fe-cbba-cf114d9d0258"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Removing stop words\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords as nltk_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x6zkaP7dNcln"
   },
   "outputs": [],
   "source": [
    "stop_nltk = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vn2HTcGNNclq"
   },
   "outputs": [],
   "source": [
    "train[\"text\"] = train[\"text\"].apply(lambda text: \" \".join(word for word in text.split() if word not in stop_nltk))\n",
    "test[\"text\"] = test[\"text\"].apply(lambda text: \" \".join(word for word in text.split() if word not in stop_nltk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "elKUaLB9N7ci"
   },
   "source": [
    "### Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6GIpPafrN7cj"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import  classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sVl1jhr6N7cn"
   },
   "outputs": [],
   "source": [
    "# Splitting the train data into train and test\n",
    "X = train['text']\n",
    "y = train['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tbUQPWenN7cq"
   },
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4kZK5HYN7cs"
   },
   "source": [
    "#### Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "by3KIVuZN7ct"
   },
   "outputs": [],
   "source": [
    "# Creating a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('v', CountVectorizer(strip_accents='ascii', max_df=0.5)),\n",
    "    ('c', MultinomialNB(fit_prior=True, class_prior=None))\n",
    "    ])\n",
    "\n",
    "# Setting parameters\n",
    "params = {\n",
    "   # 'v__max_df': [0.3,0.5,0.8],\n",
    "    'v__ngram_range': [(1,1),(1,2),(1,3),(1,4)],\n",
    "    'c__alpha': [0.25,0.5,0.75]\n",
    "}\n",
    "\n",
    "gridSearchNB1 = GridSearchCV(pipeline,params,cv=10,n_jobs=-1, scoring=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "colab_type": "code",
    "id": "mdZBPszhN7cw",
    "outputId": "30feda2c-9aed-4be5-9c98-9fc287850766"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('v',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=0.5,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents='ascii',\n",
       "                                                        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                                        tokenizer=None,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('c',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'c__alpha': [0.25, 0.5, 0.75],\n",
       "                         'v__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_macro', verbose=0)"
      ]
     },
     "execution_count": 437,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearchNB1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "id": "2dV4zUuEN7cy",
    "outputId": "91a6669b-565d-4704-c403-488ba5724611"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'c__alpha': 0.25, 'v__ngram_range': (1, 1)}\n",
      "Train Score: 0.87\n",
      "Test Score: 0.67\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters: \", gridSearchNB1.best_params_)\n",
    "print(\"Train Score: {:.2f}\".format(gridSearchNB1.score(X_train,y_train)))\n",
    "print(\"Test Score: {:.2f}\".format(gridSearchNB1.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "colab_type": "code",
    "id": "Sz7WWQX9N7c0",
    "outputId": "0500c4e6-120f-4cb1-a039-0eebc84d34d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.96      0.93      3634\n",
      "           0       0.87      0.72      0.79      1241\n",
      "           1       0.89      0.87      0.88       981\n",
      "\n",
      "    accuracy                           0.89      5856\n",
      "   macro avg       0.89      0.85      0.87      5856\n",
      "weighted avg       0.89      0.89      0.89      5856\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.91      0.86       932\n",
      "           0       0.60      0.41      0.49       295\n",
      "           1       0.69      0.64      0.66       237\n",
      "\n",
      "    accuracy                           0.76      1464\n",
      "   macro avg       0.70      0.65      0.67      1464\n",
      "weighted avg       0.75      0.76      0.75      1464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,gridSearchNB1.predict(X_train)))\n",
    "print(classification_report(y_test,gridSearchNB1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BZQLZEGdN7c4"
   },
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DWz4E4q6N7c4"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x9YEDeugN7c6"
   },
   "outputs": [],
   "source": [
    "# Creating a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('v', CountVectorizer(strip_accents='ascii', max_df =0.5)),\n",
    "    ('lr', LogisticRegression(solver='lbfgs', max_iter=10000))\n",
    "    ])\n",
    "\n",
    "# Setting parameters\n",
    "params = {\n",
    "    'v__ngram_range': [(1,1),(1,2),(1,3),(1,4)],\n",
    "    'lr__penalty': ['l1','l2'],\n",
    "    'lr__C': [0.1, 0.25, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "gridSearchLR1 = GridSearchCV(pipeline,params,cv=5,n_jobs=-1, scoring=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "colab_type": "code",
    "id": "ji9EUFpGN7c8",
    "outputId": "f5d29c64-c66b-4619-8eed-8872b81bc2e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('v',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=0.5,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents='ascii',\n",
       "                                                        token_pattern='(?u)...\n",
       "                                                           multi_class='auto',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'lr__C': [0.1, 0.25, 0.5, 1.0],\n",
       "                         'lr__penalty': ['l1', 'l2'],\n",
       "                         'v__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_macro', verbose=0)"
      ]
     },
     "execution_count": 442,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearchLR1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "id": "LGgTwcYeN7c9",
    "outputId": "a577241f-9e95-45ad-e7b3-87e48050f24a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'lr__C': 1.0, 'lr__penalty': 'l2', 'v__ngram_range': (1, 2)}\n",
      "Train Score: 0.99\n",
      "Test Score: 0.73\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters: \", gridSearchLR1.best_params_)\n",
    "print(\"Train Score: {:.2f}\".format(gridSearchLR1.score(X_train,y_train)))\n",
    "print(\"Test Score: {:.2f}\".format(gridSearchLR1.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "colab_type": "code",
    "id": "9uOtf-9iN7c_",
    "outputId": "0fac6593-307c-4bb8-e46c-6bb15f006fb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00      3634\n",
      "           0       0.98      0.98      0.98      1241\n",
      "           1       0.98      0.99      0.99       981\n",
      "\n",
      "    accuracy                           0.99      5856\n",
      "   macro avg       0.99      0.99      0.99      5856\n",
      "weighted avg       0.99      0.99      0.99      5856\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.90      0.87       932\n",
      "           0       0.63      0.57      0.60       295\n",
      "           1       0.76      0.67      0.71       237\n",
      "\n",
      "    accuracy                           0.79      1464\n",
      "   macro avg       0.75      0.71      0.73      1464\n",
      "weighted avg       0.79      0.79      0.79      1464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,gridSearchLR1.predict(X_train)))\n",
    "print(classification_report(y_test,gridSearchLR1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V7qI-nU1gd-o"
   },
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5llbnWpgcyz"
   },
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "3p_1r4Gngcy2",
    "outputId": "d5b2bb0f-87e2-4894-9405-1816cee42ebc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.85\n",
      "Test score: 0.78\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(strip_accents='ascii', max_df =0.5)\n",
    "X_trainxgb = cv.fit_transform(X_train)\n",
    "X_testxgb = cv.transform(X_test)\n",
    "\n",
    "xgb1 = XGBClassifier(objective='multi:softmax', seed=0, missing=None, max_depth=9,early_stopping_rounds = 5)\n",
    "xgb1.fit(X_trainxgb,y_train)\n",
    "\n",
    "print(\"Train score: {:.2f}\".format(xgb1.score(X_trainxgb,y_train)))\n",
    "print(\"Test score: {:.2f}\".format(xgb1.score(X_testxgb,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "colab_type": "code",
    "id": "RkHRKMRogcy4",
    "outputId": "3d55f758-dccf-4b54-87fc-01e9f586bf46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.94      0.91      3634\n",
      "           0       0.75      0.71      0.73      1241\n",
      "           1       0.86      0.73      0.79       981\n",
      "\n",
      "    accuracy                           0.85      5856\n",
      "   macro avg       0.83      0.79      0.81      5856\n",
      "weighted avg       0.85      0.85      0.85      5856\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.90      0.86       932\n",
      "           0       0.63      0.50      0.56       295\n",
      "           1       0.73      0.62      0.67       237\n",
      "\n",
      "    accuracy                           0.78      1464\n",
      "   macro avg       0.73      0.68      0.70      1464\n",
      "weighted avg       0.77      0.78      0.77      1464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,xgb1.predict(X_trainxgb)))\n",
    "print(classification_report(y_test,xgb1.predict(X_testxgb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ktCzgrBVN7dE"
   },
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "auFOgGidN7dF"
   },
   "outputs": [],
   "source": [
    "# Creating a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('v', TfidfVectorizer(norm=None, max_df=0.5)),\n",
    "    ('c', MultinomialNB(fit_prior=True, class_prior=None))\n",
    "    ])\n",
    "\n",
    "# Setting parameters\n",
    "params = {\n",
    "    'v__ngram_range': [(1,1),(1,2),(1,3),(1,4)],\n",
    "    'c__alpha': [0.25,0.5,0.75]\n",
    "}\n",
    "\n",
    "gridSearchNBtfidf1 = GridSearchCV(pipeline,params,cv=10,n_jobs=-1, scoring=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "colab_type": "code",
    "id": "P9NwjacZN7dH",
    "outputId": "bfe7281d-6cd6-423f-e700-2b93c77035d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('v',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=0.5,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm=None,\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accent...\n",
       "                                                        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                                        tokenizer=None,\n",
       "                                                        use_idf=True,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('c',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'c__alpha': [0.25, 0.5, 0.75],\n",
       "                         'v__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_macro', verbose=0)"
      ]
     },
     "execution_count": 446,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearchNBtfidf1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "id": "FtW0GUBtN7dJ",
    "outputId": "0ab0ccba-4dda-4955-d5bb-54c04a7727ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'c__alpha': 0.75, 'v__ngram_range': (1, 2)}\n",
      "Train Score: 0.98\n",
      "Test Score: 0.67\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters: \", gridSearchNBtfidf1.best_params_)\n",
    "print(\"Train Score: {:.2f}\".format(gridSearchNBtfidf1.score(X_train,y_train)))\n",
    "print(\"Test Score: {:.2f}\".format(gridSearchNBtfidf1.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "colab_type": "code",
    "id": "38x180ChN7dL",
    "outputId": "03b248ab-ea00-4db8-ae46-ae95ff4720d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.99      0.99      3634\n",
      "           0       0.98      0.96      0.97      1241\n",
      "           1       0.97      0.99      0.98       981\n",
      "\n",
      "    accuracy                           0.99      5856\n",
      "   macro avg       0.98      0.98      0.98      5856\n",
      "weighted avg       0.99      0.99      0.99      5856\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.88      0.85       932\n",
      "           0       0.56      0.43      0.49       295\n",
      "           1       0.65      0.68      0.67       237\n",
      "\n",
      "    accuracy                           0.76      1464\n",
      "   macro avg       0.68      0.66      0.67      1464\n",
      "weighted avg       0.75      0.76      0.75      1464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,gridSearchNBtfidf1.predict(X_train)))\n",
    "print(classification_report(y_test,gridSearchNBtfidf1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ExdoxUh6N7dN"
   },
   "outputs": [],
   "source": [
    "# Creating a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('v', TfidfVectorizer(norm=None, max_df=0.5)),\n",
    "    ('lr', LogisticRegression(solver='lbfgs'))\n",
    "    ])\n",
    "\n",
    "# Setting parameters\n",
    "params = {\n",
    "    'v__ngram_range': [(1,1),(1,2),(1,3),(1,4)],\n",
    "    'lr__penalty': ['l1','l2'],\n",
    "    'lr__C': [0.1, 0.25, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "gridSearchLRtfidf1 = GridSearchCV(pipeline,params,cv=5,n_jobs=-1, scoring=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "colab_type": "code",
    "id": "umF34_wxN7dP",
    "outputId": "ea0ad52f-3673-4e82-b3ce-bb66fab2aab8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('v',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=0.5,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm=None,\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents...\n",
       "                                                           multi_class='auto',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'lr__C': [0.1, 0.25, 0.5, 1.0],\n",
       "                         'lr__penalty': ['l1', 'l2'],\n",
       "                         'v__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_macro', verbose=0)"
      ]
     },
     "execution_count": 450,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearchLRtfidf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "id": "_Y4TDVOTN7dR",
    "outputId": "3f84f9c1-5ac0-41f2-cf05-e67e80a1bcad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'lr__C': 0.1, 'lr__penalty': 'l2', 'v__ngram_range': (1, 2)}\n",
      "Train Score: 0.99\n",
      "Test Score: 0.73\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters: \", gridSearchLRtfidf1.best_params_)\n",
    "print(\"Train Score: {:.2f}\".format(gridSearchLRtfidf1.score(X_train,y_train)))\n",
    "print(\"Test Score: {:.2f}\".format(gridSearchLRtfidf1.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "colab_type": "code",
    "id": "uFHfAtHQN7dU",
    "outputId": "13f919d7-fe99-4abd-8b13-5e52a1cbb369"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00      3634\n",
      "           0       0.99      0.99      0.99      1241\n",
      "           1       0.99      0.99      0.99       981\n",
      "\n",
      "    accuracy                           1.00      5856\n",
      "   macro avg       0.99      0.99      0.99      5856\n",
      "weighted avg       1.00      1.00      1.00      5856\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.90      0.87       932\n",
      "           0       0.63      0.57      0.60       295\n",
      "           1       0.78      0.68      0.73       237\n",
      "\n",
      "    accuracy                           0.80      1464\n",
      "   macro avg       0.75      0.72      0.73      1464\n",
      "weighted avg       0.79      0.80      0.79      1464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,gridSearchLRtfidf1.predict(X_train)))\n",
    "print(classification_report(y_test,gridSearchLRtfidf1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZmV4L9x_g8rs"
   },
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-yaNySc0g7r8"
   },
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "1GE4Cimvg7sA",
    "outputId": "e929c4aa-981e-49d1-d975-23923204ddae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.85\n",
      "Test score: 0.78\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(norm=None, max_df =0.5)\n",
    "X_trainxgb = tfidf.fit_transform(X_train)\n",
    "X_testxgb = tfidf.transform(X_test)\n",
    "\n",
    "xgbtfidf1 = XGBClassifier(objective='multi:softmax', seed=0, missing=None, max_depth=9,early_stopping_rounds = 5)\n",
    "xgbtfidf1.fit(X_trainxgb,y_train)\n",
    "\n",
    "print(\"Train score: {:.2f}\".format(xgbtfidf1.score(X_trainxgb,y_train)))\n",
    "print(\"Test score: {:.2f}\".format(xgbtfidf1.score(X_testxgb,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "colab_type": "code",
    "id": "zOrs0oNPg7sD",
    "outputId": "4dfd5145-a7dd-487d-a146-f32d91fa6dbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.94      0.91      3634\n",
      "           0       0.75      0.71      0.73      1241\n",
      "           1       0.86      0.73      0.79       981\n",
      "\n",
      "    accuracy                           0.85      5856\n",
      "   macro avg       0.83      0.79      0.81      5856\n",
      "weighted avg       0.85      0.85      0.85      5856\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.90      0.86       932\n",
      "           0       0.63      0.50      0.56       295\n",
      "           1       0.73      0.62      0.67       237\n",
      "\n",
      "    accuracy                           0.78      1464\n",
      "   macro avg       0.73      0.68      0.70      1464\n",
      "weighted avg       0.77      0.78      0.77      1464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,xgbtfidf1.predict(X_trainxgb)))\n",
    "print(classification_report(y_test,xgbtfidf1.predict(X_testxgb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yft_ue_oQY2x"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "I observed following key points:\n",
    "1. Stemming gave better accuracy than lemmitization.\n",
    "2. Keeping stop words helped in improving accuracy, since sentiment analysis is sensitive to stop words.\n",
    "3. Count Vectorization was better than tfidf in this case. \n",
    "\n",
    "Finally out of all models, XGBoost prevented overfitting however it didn't improve F1 score.\n",
    "\n",
    "Logistic Regression without removing stop words gave the best F1 macro score. Hence, I decided to use it for my final prediction.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7tuTSvDmkyY_"
   },
   "source": [
    "# Final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IDUqBwVlQXu9"
   },
   "outputs": [],
   "source": [
    "# predicting outcome for test data \n",
    "test1 = pd.read_csv(\"test.csv\", encoding='ISO-8859-1')\n",
    "test1['Target'] = gridSearchLR.predict(test['text'])\n",
    "test1 = test1.drop(['text'], axis=1)\n",
    "test1.to_csv('final_pred.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sxb176930_homework1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
